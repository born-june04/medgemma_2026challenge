use_stub_encoders: false
audio_checkpoint: "google/hear-pytorch"
# MedSigLIP model id (update if you want a different checkpoint)
image_checkpoint: "google/medsiglip-448"
llm_adapter: placeholder
hf_token: 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

physiology:
  enabled: False
  output_dir: "outputs/evidence/physiology"

report:
  enabled: True
  # Set to a HF text model id (e.g., a MedGemma instruction-tuned checkpoint you have access to)
  model_id: "google/medgemma-1.5-4b-it"
  # Optional: run report generation in a separate Python environment to avoid transformers version conflicts.
  # Example: "/gscratch/scrubbed/june0604/conda-envs/medgemma/bin/python"
  python_exe: ""
  output_dir: "outputs/reports"
  max_new_tokens: 512
  temperature: 0.2

# --- Audio classifier head (new) ---
audio_classifier:
  enabled: true                          # When true, pipeline can run classifier inference if ckpt exists
  checkpoint_path: artifacts/audio_classifier_head.pt
  balanced_sampling: true

  # Training is a separate, explicit step. Keep this false unless your training script wants to use it.
  auto_train_if_missing: false

  # IMPORTANT: Set this to the 'dataset' directory level:
  #   <dataset_root>/
  #     <class_A>/CSI/*.png
  #     <class_B>/CSI/*.png
  dataset_root: "data/Chest_Diseases_Dataset"

  # Where to store the cached embeddings from the frozen encoder (for fast training)
  cache_path: artifacts/audio_embeddings_cache.pt

  # Head architecture: null => Linear head; set an integer (e.g., 256) for a tiny MLP
  hidden_dim: 768 ## 768 -> best acc = 0.875
  dropout: 0.0

  # Training hyperparameters (used only by the training step)
  batch_size: 36
  lr: 0.001
  weight_decay: 0.0001
  max_epochs: 1024
  val_ratio: 0.2
  early_stopping_patience: 1024
  amp: False

# --- Image classifier head (CXR) ---
image_classifier:
  enabled: true
  checkpoint_path: artifacts/image_classifier_head.pt
  balanced_sampling: true
  dataset_root: "data/Chest_Diseases_Dataset"
  cache_path: artifacts/image_embeddings_cache.pt
  hidden_dim: 768
  dropout: 0.0
  batch_size: 36
  lr: 0.001
  weight_decay: 0.0001
  max_epochs: 1024
  val_ratio: 0.2
  early_stopping_patience: 1024
  amp: False

image_finetune:
  enabled: False
  batch_size: 9
  lr_attn: 0.000001
  lr_head: 0.0001
  weight_decay: 0.0001
  max_epochs: 50
  val_ratio: 0.2
  amp: True
  balanced_sampling: True

gradcam:
  enabled: True
  targets: ["occlusion"] # occlusion (mean baseline; increase+decrease overlays)
  output_dir: "outputs/gradcam"
  alpha: 0.3
